services:
  ollama:
    image: ollama/ollama  # Use the official olama image
    container_name: ollama
    volumes:
      - ./ollama/ollama:/root/.ollama
      - ./ollama/ollama-entrypoint.sh:/entrypoint.sh
    ports:
      - 11434:11434 # Adjust this port as per your API needs
    restart: always
    entrypoint: ["/usr/bin/bash", "/entrypoint.sh"]
    networks:
      - backend-network
    healthcheck:
      test: ollama list || exit 1
      interval: 10s
      timeout: 30s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: all

  api:
    container_name: api
    build: ./backend
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_healthy
    networks:
      - backend-network
    env_file:
      -  ./backend/.env
    ports:
      - 8000:8000
    env_file:
      - ./backend/.env

  frontend:
    container_name: frontend
    build:
      context: ./frontend/pdf-chat
    networks:
      - backend-network
    ports:
      - 4200:80
    depends_on:
      - api
    environment:
      - NODE_ENV=production

  postgres:
    container_name: postgres
    image: ankane/pgvector:latest
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U pdf_chat_user -d pdf_chat"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - backend-network
    ports:
      - 5432:5432
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./backend/database/init.sql:/docker-entrypoint-initdb.d/init.sql
    environment:
      - POSTGRES_PASSWORD=5uperSecr3tP@ssw0rd!
      - POSTGRES_USER=pdf_chat_user
      - POSTGRES_DB=pdf_chat

networks:
  backend-network:
    driver: bridge

volumes:
  postgres-data:
